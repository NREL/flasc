{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out hoger in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ruptures as rpt\n",
    "from floris.utilities import wrap_180, wrap_360\n",
    "\n",
    "from flasc import FlascDataFrame\n",
    "from flasc.utilities.circular_statistics import calc_wd_mean_radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(x: np.ndarray, threshold: float = 100) -> np.ndarray:\n",
    "    \"\"\"Discretize data points into segments.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Data to discretize.\n",
    "        threshold (float, optional): Threshold for discretization. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Discretized data.\n",
    "    \"\"\"\n",
    "    # Handle NA values\n",
    "    na = pd.isna(x)\n",
    "\n",
    "    # Sort indices\n",
    "    o = np.argsort(x)\n",
    "    x_sorted = x[o]\n",
    "\n",
    "    # Initialize group labels\n",
    "    y = np.ones(len(x_sorted))\n",
    "\n",
    "    # Find significant jumps\n",
    "    d = np.diff(x_sorted)\n",
    "    w = np.where(d >= threshold)[0]\n",
    "\n",
    "    # Assign group labels\n",
    "    for i in range(len(d)):\n",
    "        if i in w:\n",
    "            y[i + 1 :] += 1\n",
    "\n",
    "    # Reorder and handle NAs\n",
    "    y = y[np.argsort(o)]\n",
    "    y[na] = np.nan\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('scada_exemple.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100\n",
    "reference = 'last'\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure in FlascDataFrame format\n",
    "df = FlascDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reference == \"first\":\n",
    "    ref = 0\n",
    "elif reference == \"last\":\n",
    "    ref = len(df) - 1\n",
    "else:\n",
    "    try:\n",
    "        ref = np.argmin(np.abs(df[\"time\"].values - pd.to_datetime(reference)))\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            \"Invalid reference point. Please use 'first', 'last', or a valid time string.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results dataframe\n",
    "df_jump = pd.DataFrame(columns=[\"Knot\", \"Jump\", \"Turbine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing turbine 0\n",
      "...with turbine 1\n",
      " Number of jumps: 481\n",
      "...with turbine 2\n",
      " Number of jumps: 481\n",
      "...with turbine 3\n",
      " Number of jumps: 481\n",
      "...with turbine 4\n",
      " Number of jumps: 481\n",
      "...with turbine 5\n",
      " Number of jumps: 481\n",
      "...with turbine 6\n",
      " Number of jumps: 481\n",
      "...with turbine 7\n",
      " Number of jumps: 481\n",
      "...with turbine 8\n",
      " Number of jumps: 481\n",
      "...with turbine 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 31\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# R code uses picor: Piecewise-constant regression, using\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# https://github.com/chasmani/piecewise-regression in python\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# as a replacement for picor\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# https://github.com/deepcharles/ruptures\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# presumably can improve somewhat\u001b[39;00m\n\u001b[1;32m     30\u001b[0m algo \u001b[38;5;241m=\u001b[39m rpt\u001b[38;5;241m.\u001b[39mPelt(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m\"\u001b[39m, min_size\u001b[38;5;241m=\u001b[39mthreshold)\u001b[38;5;241m.\u001b[39mfit(wrapped_error)\n\u001b[0;32m---> 31\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# algo = rpt.Window(width=threshold, model='l1').fit(wrapped_error)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# pen = 20 # np.log(len(wrapped_error)) * np.nanstd(wrapped_error)**2\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# print(f\"Pen: {pen}\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# If results is length 1 or 0, no significant jumps detected, continue\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/FLASC/flasc/.venv/lib/python3.13/site-packages/ruptures/detection/pelt.py:130\u001b[0m, in \u001b[0;36mPelt.predict\u001b[0;34m(self, pen)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sanity_check(\n\u001b[1;32m    123\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    124\u001b[0m     n_bkps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    125\u001b[0m     jump\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjump,\n\u001b[1;32m    126\u001b[0m     min_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_size,\n\u001b[1;32m    127\u001b[0m ):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadSegmentationParameters\n\u001b[0;32m--> 130\u001b[0m partition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_seg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m bkps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(e \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m partition\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bkps\n",
      "File \u001b[0;32m~/Projects/FLASC/flasc/.venv/lib/python3.13/site-packages/ruptures/detection/pelt.py:71\u001b[0m, in \u001b[0;36mPelt._seg\u001b[0;34m(self, pen)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# we update with the right partition\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     tmp_partition\u001b[38;5;241m.\u001b[39mupdate({(t, bkp): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbkp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m pen})\n\u001b[1;32m     72\u001b[0m     subproblems\u001b[38;5;241m.\u001b[39mappend(tmp_partition)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# finding the optimal partition\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/FLASC/flasc/.venv/lib/python3.13/site-packages/ruptures/costs/costl1.py:50\u001b[0m, in \u001b[0;36mCostL1.error\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotEnoughPoints\n\u001b[1;32m     49\u001b[0m sub \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal[start:end]\n\u001b[0;32m---> 50\u001b[0m med \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(sub \u001b[38;5;241m-\u001b[39m med)\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/Projects/FLASC/flasc/.venv/lib/python3.13/site-packages/numpy/lib/function_base.py:3927\u001b[0m, in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3845\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_median_dispatcher)\n\u001b[1;32m   3846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, overwrite_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3847\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3848\u001b[0m \u001b[38;5;124;03m    Compute the median along the specified axis.\u001b[39;00m\n\u001b[1;32m   3849\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3925\u001b[0m \n\u001b[1;32m   3926\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_median\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3928\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/FLASC/flasc/.venv/lib/python3.13/site-packages/numpy/lib/function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   3820\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[1;32m   3821\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[0;32m-> 3823\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Projects/FLASC/flasc/.venv/lib/python3.13/site-packages/numpy/lib/function_base.py:3960\u001b[0m, in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3958\u001b[0m         part \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m   3959\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3960\u001b[0m     part \u001b[38;5;241m=\u001b[39m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m part\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m   3963\u001b[0m     \u001b[38;5;66;03m# make 0-D arrays work\u001b[39;00m\n\u001b[1;32m   3964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m part\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Projects/FLASC/flasc/.venv/lib/python3.13/site-packages/numpy/core/fromnumeric.py:771\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m     a \u001b[38;5;241m=\u001b[39m asanyarray(a)\u001b[38;5;241m.\u001b[39mcopy(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 771\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop over combinations of turbines\n",
    "for t_i in range(df.n_turbines):\n",
    "    t_i_col = \"wd_%03d\" % t_i\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Processing turbine {t_i}\")\n",
    "\n",
    "    for t_j in range(df.n_turbines):\n",
    "        if t_i == t_j:\n",
    "            continue\n",
    "        t_j_col = \"wd_%03d\" % t_j\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"...with turbine {t_j}\")\n",
    "\n",
    "        # Compute the wrapped error\n",
    "        wrapped_error = wrap_180(df[t_i_col].values - df[t_j_col].values)\n",
    "\n",
    "        # R code uses picor: Piecewise-constant regression, using\n",
    "        # https://github.com/chasmani/piecewise-regression in python\n",
    "        # as a replacement for picor\n",
    "        # I can't find a close python equivalent for picor, so starting with ruptures\n",
    "        # this is convenient as via the dependency on wind-up this is already\n",
    "        # a defacto requirement for FLASC\n",
    "\n",
    "        # Note these first lines (minus the threshold)\n",
    "        # are verbatim from the example here\n",
    "        # https://github.com/deepcharles/ruptures\n",
    "        # presumably can improve somewhat\n",
    "        algo = rpt.Pelt(model=\"l1\", min_size=threshold).fit(wrapped_error)\n",
    "        result = algo.predict(pen=5000)\n",
    "        # algo = rpt.Window(width=threshold, model='l1').fit(wrapped_error)\n",
    "        # pen = 20 # np.log(len(wrapped_error)) * np.nanstd(wrapped_error)**2\n",
    "        # print(f\"Pen: {pen}\")\n",
    "        # result = algo.predict(pen=pen)\n",
    "        break\n",
    "    break\n",
    "\n",
    "        # # If results is length 1 or 0, no significant jumps detected, continue\n",
    "        # if len(result) <= 1:\n",
    "        #     if verbose:\n",
    "        #         print(\"... No significant jumps detected\")\n",
    "        #     continue\n",
    "\n",
    "        # if verbose:\n",
    "        #     # print(f\"... Jumps detected at: {result[:-1]}\")\n",
    "        #     print(f\" Number of jumps: {len(result)-1}\")\n",
    "\n",
    "        # # Compute the mean values in error in each of the identified segments\n",
    "        # # so we can compute the jump size at each jump location\n",
    "        # knots = result[:-1]  # Exclude the end point returned by ruptures\n",
    "        # values = [\n",
    "        #     calc_wd_mean_radial(wrapped_error[start:end])\n",
    "        #     for start, end in zip([0] + knots, knots + [len(wrapped_error)])\n",
    "        # ]\n",
    "\n",
    "        # # Paul's note: I added wrap_180 here though I don't think it's in original R code\n",
    "        # # but it feels correct to me to include it since errors \n",
    "        # # should not include values > abs(180)\n",
    "        # values = [wrap_180(v) for v in values]\n",
    "\n",
    "        # # if verbose:\n",
    "        # #     print(f\"... Jump values per area: {values}\")\n",
    "\n",
    "        # jumps = np.diff(values)\n",
    "\n",
    "        # # if verbose:\n",
    "        # #     print(f\"... Jump sizes: {jumps}\")\n",
    "\n",
    "        # # Append result to the result dataframe\n",
    "        # # TODO: Not a big deal but this is a slow way to do it\n",
    "        # df_jump = pd.concat(\n",
    "        #     [df_jump, pd.DataFrame({\"Knot\": knots, \"Jump\": jumps, \"Turbine\": t_i})]\n",
    "        # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Knot</th>\n",
       "      <th>Jump</th>\n",
       "      <th>Turbine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Knot, Jump, Turbine]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
